Shusen Wang
============



>  Assistant Professor,
>  Department of Computer Science,
>  Stevens Institute of Technology



**Phone:** (201)216-5485  &nbsp; &nbsp;  **Email:** shusen.wang@stevens.edu  &nbsp; &nbsp; **Homepage:** wangshusen.github.io



Research
---------

Keywords
:   Machine learning (ML), randomized linear algebra, optimization, big data, distributed computing.


Summary
:   My expertise is in statistical ML, computational methods for ML, and deep learning.  I am most interested in practical, scalable, and sound algorithms for learning from big data. In the past, I developed randomized algorithms for making matrix computation, numerical optimization, and machine learning faster and more scalable. My current research is focused on communication-efficiency and privacy-preserving algorithms for federated learning.


Work Experience
----------

from 2018
:   **Tenure-track assistant professor**; Department of Computer Science, Stevens Institute of Technology (Hoboken, NJ, USA)

2016-2018
:   **Postdoctoral Scholar**; Department of Statistics, UC Berkeley (Berkeley, CA, USA)

    *Advisor: Michael W. Mahoney*

    *Research: randomized linear algebra and implementation*

2014-2015
:   **Research Intern**; Baidu Big Data Lab (Beijing, China)

    *Mentor: Tong Zhang*

    *Research: optimization algorithms*

2012
:   **Research Intern**; Google Research (Beijing, China)

    *Research: randomized algorithms*
    
2011-2012
:   **Intern**; Microsoft Research Asia (Beijing, China)

    *Mentors: Haixun Wang and Yangqiu Song*

    *Project: probabilistic knowledge base*
    
    
Education
---------

2011-2016
:   **Doctor of Engineering**; Zhejiang University (Hangzhou, China)

    *Major: Computer Science*
    
    *Advisor: Zhihua Zhang*

    *Thesis: Large-Scale Machine Learning: A Randomized Approach and Theoretical Analysis*

2007-2011
:   **Bachelor of Engineering**; Zhejiang University (Hangzhou, China)

    *Major: Computer Science*


    
Academic Service
--------------------

* **Journal Reviewer**

     * Journal of Machine Learning Research, 2015 to 2020
     * SIAM Journal on Scientific Computing, 2017
     * ACM Transactions on Mathematical Software, 2017
     * Journal of Econometrics, 2017
     * SIAM Journal on Matrix Analysis and Applications, 2017, 2019
     * Pattern Recognition Letters, 2018
     * International Journal of Data Science and Analytics, 2018
     * IEEE Transactions on Signal Processing, 2018
     * IEEE Transactions on Information Theory, 2019
     * IEEE Transactions on Pattern Analysis and Machine Intelligence, 2019




* **Conference Committee Member or Reviewer**

     * NIPS 2014, 2015, 2017, 2018, 2020
     * ICML 2017, 2018, 2019
     * IJCAI 2015, 2017, 2018, 2019, 2020
     * AAAI 2017, 2018, 2020
     * AISTATS 2019, 2020
     * UAI 2019, 2020
     * Supercomputing (SC) 2019


Major Honors & Awards
--------------------

2014
:   **Baidu Scholarship**, awarded to 8 Chinese students in the world, US$30,000

2013
:   **Microsoft Research Asia Fellow**,
awarded to 10 students in Asia Pacific, US$10,000

2012
:   **Scholarship Award for Excellent Doctoral Student Granted by Ministry of Education**, US$5,000

2012-2014
:   **National Scholarship for Graduate Students**, 3 times, each time US$5,000



Journal Papers
--------------------
* [A Bootstrap Method for Error Estimation in Randomized Matrix Multiplication.](http://wangshusen.github.io/papers/JMLR2019B.pdf)
Miles E. Lopes, **Shusen Wang**, Michael W. Mahoney.
*Journal of Machine Learning Research* (**JMLR**), 20(39):1-40, 2019.

* [Scalable Kernel K-Means Clustering with Nystrom Approximation: Relative-Error Bounds.](http://wangshusen.github.io/papers/JMLR2019A.pdf)
**Shusen Wang**, Alex Gittens, and Michael W. Mahoney.
*Journal of Machine Learning Research* (**JMLR**), 20(12):1-49, 2019.

* [Sketched Ridge Regression: Optimization Perspective, Statistical Perspective, and Model Averaging.](http://wangshusen.github.io/papers/JMLR2018.pdf)
**Shusen Wang**, Alex Gittens, and Michael W. Mahoney.
*Journal of Machine Learning Research* (**JMLR**), 18:1-50, 2018.

* [Efficient Data-Driven Geologic Feature Characterization from Pre-stack Seismic Measurements using Randomized Machine-Learning Algorithm.](http://wangshusen.github.io/papers/GJI2018.pdf)
Youzuo Lin, **Shusen Wang**, Jayaraman Thiagarajan, George Guthrie, and David Coblentz.
*Geophysical Journal International*, ggy385, 2018. 

* [Alchemist: An Apache Spark <=> MPI Interface.]()
Alex Gittens, Kai Rothauge, Michael W. Mahoney, **Shusen Wang**, Lisa Gerhardt, Prabhat, Jey Kottalam, Michael Ringenburg, and Kristyn Maschhoff.
*Concurrency and Computation Practice and Experience* (**CCPE**), Special Issue on the Cray User Group, to appear, 2018.

* [Towards More Efficient SPSD Matrix Approximation and CUR Matrix Decomposition](http://wangshusen.github.io/papers/JMLR2016b.pdf).
**Shusen Wang**, Zhihua Zhang, and Tong Zhang.
*Journal of Machine Learning Research* (**JMLR**), 17(210):1-49, 2016.

* [SPSD Matrix Approximation vis Column Selection: Theories, Algorithms, and Extensions.](http://wangshusen.github.io/papers/JMLR2016.pdf)
**Shusen Wang**, Luo Luo, and Zhihua Zhang.
*Journal of Machine Learning Research* (**JMLR**), 17(49):1-49, 2016. 

* [Improving CUR Matrix Decomposition and the Nystrom Approximation via Adaptive Sampling.](http://wangshusen.github.io/papers/JMLR2013.pdf)
**Shusen Wang** and Zhihua Zhang. 
*Journal of Machine Learning Research* (**JMLR**), 14: 2729-2769, 2013.

* [EP-GIG Priors and Applications in Bayesian Sparse Learning.](http://wangshusen.github.io/papers/JMLR2012.pdf)
Zhihua Zhang, **Shusen Wang**, Dehua Liu, and Michael I. Jordan.
*Journal of Machine Learning Research* (**JMLR**), 13: 2031-2061, 2012.



Conference Papers
--------------------
* [On the Convergence of FedAvg on Non-IID Data.](http://arxiv.org/abs/1907.02189)
Xiang Li, Kaixuan Huang, Wenhao Yang, **Shusen Wang**, and Zhihua Zhang.
In *International Conference on Learning Representations* (**ICLR**), 2020.

* [Do Subsampled Newton Methods Work for High-Dimensional Data?](http://arxiv.org/abs/1902.04952)
Xiang Li, **Shusen Wang**, and Zhihua Zhang.
In *AAAI Conference on Artificial Intelligence* (**AAAI**), 2020.

* [Sharper Generalization Bound for the Divide-and-Conquer Ridge Regression.]() 
**Shusen Wang**. In *AAAI Conference on Artificial Intelligence* (**AAAI**), 2019.

* [GIANT: Globally Improved Approximate Newton Method for Distributed Optimization.]()
**Shusen Wang**, Farbod Roosta-Khorasani, Peng Xu, and Michael W. Mahoney. In *Advances in Neural Information Processing Systems* (**NIPS**), 2018.

* [Error Estimation for Randomized Least-Squares Algorithms via the Bootstrap.](https://arxiv.org/abs/1803.08021)
Miles E. Lopes, **Shusen Wang**, and Michael W. Mahoney.
In *International Conference on Machine Learning* (**ICML**), 2018.

* [Accelerating Large-Scale Data Analysis by Offloading to High-Performance Computing Libraries using Alchemist.]()
Alex Gittens, Kai Rothauge, **Shusen Wang**, Michael W. Mahoney, Lisa Gerhardt, Prabhat, Jey Kottalam, Michael Ringenburg, and Kristyn Maschhoff. 
In *ACM SIGKDD Conference on Knowledge Discovery and Data Mining* (**KDD**), 2018.

* [OverSketch: Approximate Matrix Multiplication for the Cloud.]()
Vipul Gupta, **Shusen Wang**, Thomas Courtade, and Kannan Ramchandran.
In *IEEE International Conference on Big Data*, 2018.

* [Sketched Ridge Regression: Optimization Perspective, Statistical Perspective, and Model Averaging.](http://wangshusen.github.io/papers/ICML2017.pdf)
**Shusen Wang**, Alex Gittens, and Michael W. Mahoney.
In *International Conference on Machine Learning* (**ICML**), 2017.

* [Towards Real-Time Geologic Feature Detection from Seismic Measurements using a Randomized Machine-Learning Algorithm.]()
Youzuo Lin, **Shusen Wang**, Jayaraman Thiagarajan, George Guthrie, and David Coblentz.
In *Proceeding of Society of Exploration Geophysics* (**SEG**), 2017.


* [Open Domain Short Text Conceptualization: A Generative + Descriptive Modeling Approach.]()
Yangqiu Song, **Shusen Wang**, and Haixun Wang.
In *International Joint Conference on Artificial Intelligence* (**IJCAI**), 2015.

* [Improving the Modified Nystrom Method Using Spectral Shifting.]()
**Shusen Wang**, Chao Zhang, Hui Qian, and Zhihua Zhang.
In *the 20th ACM SIGKDD Conference on Knowledge Discovery and Data Mining* (**KDD**), 2014.

* [Efficient Algorithms and Error Analysis for the Modified Nystrom Method.]()
**Shusen Wang** and Zhihua Zhang.
In *Proceedings of the 17th International Conference on Artificial Intelligence and Statistics, JMLR W&CP* (**AISTATS**), 2014.

* [Making Fisher Discriminant Analysis Scalable.]()
Bojun Tu, Zhihua Zhang, **Shusen Wang**, and Hui Qian.
In *the International Conference on Machine Learning* (**ICML**), 2014.

* [Exact Subspace Clustering in Linear Time.]()
**Shusen Wang**, Bojun Tu, Congfu Xu, and Zhihua Zhang.
In *the 28th AAAI Conference on Artificial Intelligence* (**AAAI**), 2014.

* [Using The Matrix Ridge Approximation to Speedup Determinantal Point Processes Sampling Algorithms.]()
**Shusen Wang**, Chao Zhang, Hui Qian, and Zhihua Zhang.
In *the 28th AAAI Conference on Artificial Intelligence* (**AAAI**), 2014.

* [Transfer Understanding from Head Queries to Tail Queries.]()
Yangqiu Song, Haixun Wang, Weizhu Chen, and **Shusen Wang**.
In *the 23rd ACM International Conference on Information and Knowledge Management* (**CIKM**), 2014.

* [Nonconvex Relaxation Approaches to Robust Matrix Recovery.]()
**Shusen Wang**, Dehua Liu, and Zhihua Zhang.
In *International Joint Conference on Artificial Intelligence* (**IJCAI**), 2013.

* [A Scalable CUR Matrix Decomposition Algorithm: Lower Time Complexity and Tighter Bound.]()
**Shusen Wang** and Zhihua Zhang.
In *Advances in Neural Information Processing Systems* (**NIPS**), 2012.

* [Colorization by Matrix Completion.]()
**Shusen Wang** and Zhihua Zhang.
In *the 26th AAAI Conference on Artificial Intelligence* (**AAAI**), 2012.

* [Efficient Subspace Segmentation via Quadratic Programming.]()
**Shusen Wang**, Xiaotong Yuan, Tiansheng Yao, Shuicheng Yan, and Jialie Shen. 
In *the 25th AAAI Conference on Artificial Intelligence* (**AAAI**), 2011.


Teaching
--------------------
* CS583: Deep Learning, Spring 2021.

* CS600: Advanced Algorithms, Fall 2020.

* CS583: Deep Learning, Spring 2020.

* CS583: Deep Learning, Fall 2019.

* CS583: Deep Learning, Spring 2019.

* Open courses on YouTube: [[English Channel](https://www.youtube.com/c/ShusenWangEng)] [[Chinese Channel](https://www.youtube.com/c/ShusenWang)]

